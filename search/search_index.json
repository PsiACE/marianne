{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"marianne marianne - the best search engine, just for fun License This library is licensed under either of: MIT license LICENSE-MIT or http://opensource.org/licenses/MIT Apache License 2.0 LICENSE-APACHE or https://opensource.org/licenses/Apache-2.0 at your option.","title":"Home"},{"location":"#marianne","text":"marianne - the best search engine, just for fun","title":"marianne"},{"location":"#license","text":"This library is licensed under either of: MIT license LICENSE-MIT or http://opensource.org/licenses/MIT Apache License 2.0 LICENSE-APACHE or https://opensource.org/licenses/Apache-2.0 at your option.","title":"License"},{"location":"slides/overview/","text":"marianne the best search engine, just for fun this slide powered by reveal.js and mkdocs What, Why & How What marianne is a search engine that started from scratch. A search engine is a software system designed to carry out web searches. -- Wikipedia - Search engine -- As we know, Google, Baidu, Bing, these are all search engines. -- Unlike the sophisticated and large commercial systems mentioned above, marianne just works. but is also ... Features Designed for the World Wide Web Powered by Machine Learning Why It has to be admitted that it was born out of homework. However, there are still a number of reasons . -- Commercial systems are often large and complex and we need some simpler examples to show how search engines work, for learning purposes. -- Hackers might take a stand against the misuse of information gathering and want to try something interesting. Although there is now duckduckgo, but nothing more fun than making some tangible improvements yourself. How Similar to other search engines, marianne performs this workflow -- Crawl submitted url, to obtain webpage metadata Analyse text and assign labels Search the database and return results to users Tech Details Crawl Almost identical to other crawlers, but with a few differences -- For world-wide web -- Urls need to be dealt with more effectively def url_sanitize(url): \"\"\"Sanitize url.\"\"\" if (url.startswith('\"') and url.endswith('\"')) or ( url.startswith(\"'\") and url.endswith(\"'\") ): url = url[1:-1] ... return url -- Increased need to focus on quality of content def classify_text(url, desc): \"\"\"Classify text.\"\"\" desc_class = predict_text(desc) if desc_class == \"spam\": print(\"[!] Website may be spam ->\", url) return \"spam\" else: return \"ham\" Analyse Introducing machine learning for basic labelling -- A plain idea is that we can try to screen pages that may be full of marketing/unwanted information to avoid users taking the risk of losing their assets. -- We introduce a random forest model and build a lightweight model, based on the spam text dataset. label text 0 ham Go until jurong point, crazy.. Available only ... 1 ham Ok lar... Joking wif u oni... 2 spam Free entry in 2 a wkly comp to win FA Cup fina... 3 ham U dun say so early hor... U c already then say... 4 ham Nah I don't think he goes to usf, he lives aro... -- Random forest is a supervised machine learning algorithm, it is ccurate, simple and flexible. -- We treat this as a binary classification problem and train and store models for it. def init_model(): ... vc = CountVectorizer() x_train_counts = vc.fit_transform(data[\"text\"]) model = RandomForestClassifier(n_estimators=100) model.fit(x_train_counts, data[\"label\"]) joblib.dump( model, current_app.config[\"SPAM_DETECT_MODEL\"] + \"/\" + \"randomforest.model\" ) joblib.dump(vc, current_app.config[\"SPAM_DETECT_MODEL\"] + \"/\" + \"randomforest.vc\") Search Interacting with users -- In fact, there are still many details that could be explained here, such as indexing and pagerank, but let's skip those. SELECT * FROM METADATA ORDER BY title -- Search -- Result Stack marianne uses pdm to manage the development environment and ... -- for app flask joblib pandas sklearn beautifulsoup4 -- for doc mkdocs mkdocs-material reveal.js -- for lint and test tox pre-commit black, flake8, codespell, isort, mypy pytest -- Perhaps we can consider it to be an engineered and well-structured project. Future Better Rank and Index More Meaningful Learning Better Performance Provide Public Sites","title":"Overview"},{"location":"slides/overview/#marianne","text":"","title":"marianne"},{"location":"slides/overview/#the-best-search-engine-just-for-fun","text":"this slide powered by reveal.js and mkdocs","title":"the best search engine, just for fun"},{"location":"slides/overview/#what-why-how","text":"","title":"What, Why &amp; How"},{"location":"slides/overview/#what","text":"marianne is a search engine that started from scratch. A search engine is a software system designed to carry out web searches. -- Wikipedia - Search engine -- As we know, Google, Baidu, Bing, these are all search engines. -- Unlike the sophisticated and large commercial systems mentioned above, marianne just works. but is also ...","title":"What"},{"location":"slides/overview/#why","text":"It has to be admitted that it was born out of homework. However, there are still a number of","title":"Why"},{"location":"slides/overview/#how","text":"Similar to other search engines, marianne performs this","title":"How"},{"location":"slides/overview/#tech-details","text":"","title":"Tech Details"},{"location":"slides/overview/#crawl","text":"Almost identical to other crawlers, but with a few differences -- For world-wide web -- Urls need to be dealt with more effectively def url_sanitize(url): \"\"\"Sanitize url.\"\"\" if (url.startswith('\"') and url.endswith('\"')) or ( url.startswith(\"'\") and url.endswith(\"'\") ): url = url[1:-1] ... return url -- Increased need to focus on quality of content def classify_text(url, desc): \"\"\"Classify text.\"\"\" desc_class = predict_text(desc) if desc_class == \"spam\": print(\"[!] Website may be spam ->\", url) return \"spam\" else: return \"ham\"","title":"Crawl"},{"location":"slides/overview/#analyse","text":"Introducing machine learning for basic labelling -- A plain idea is that we can try to screen pages that may be full of marketing/unwanted information to avoid users taking the risk of losing their assets. -- We introduce a random forest model and build a lightweight model, based on the spam text dataset. label text 0 ham Go until jurong point, crazy.. Available only ... 1 ham Ok lar... Joking wif u oni... 2 spam Free entry in 2 a wkly comp to win FA Cup fina... 3 ham U dun say so early hor... U c already then say... 4 ham Nah I don't think he goes to usf, he lives aro... -- Random forest is a supervised machine learning algorithm, it is ccurate, simple and flexible. -- We treat this as a binary classification problem and train and store models for it. def init_model(): ... vc = CountVectorizer() x_train_counts = vc.fit_transform(data[\"text\"]) model = RandomForestClassifier(n_estimators=100) model.fit(x_train_counts, data[\"label\"]) joblib.dump( model, current_app.config[\"SPAM_DETECT_MODEL\"] + \"/\" + \"randomforest.model\" ) joblib.dump(vc, current_app.config[\"SPAM_DETECT_MODEL\"] + \"/\" + \"randomforest.vc\")","title":"Analyse"},{"location":"slides/overview/#search","text":"Interacting with users -- In fact, there are still many details that could be explained here, such as indexing and pagerank, but let's skip those. SELECT * FROM METADATA ORDER BY title -- Search -- Result","title":"Search"},{"location":"slides/overview/#stack","text":"marianne uses pdm to manage the development environment and ... -- for app flask joblib pandas sklearn beautifulsoup4 -- for doc mkdocs mkdocs-material reveal.js -- for lint and test tox pre-commit black, flake8, codespell, isort, mypy pytest -- Perhaps we can consider it to be an engineered and well-structured project.","title":"Stack"},{"location":"slides/overview/#future","text":"Better Rank and Index More Meaningful Learning Better Performance Provide Public Sites","title":"Future"}]}